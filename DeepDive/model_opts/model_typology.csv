model,train_type,train_data,architecture,model_class,task_cluster,model_display_name,description,model_source,model_source_url,weights_url
alexnet,classification,imagenet,alexnet,Convolutional,Semantic,AlexNet,AlexNet trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg11,classification,imagenet,vgg11,Convolutional,Semantic,VGG11,VGG11 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg13,classification,imagenet,vgg13,Convolutional,Semantic,VGG13,VGG13 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg16,classification,imagenet,vgg16,Convolutional,Semantic,VGG16,VGG16 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg19,classification,imagenet,vgg19,Convolutional,Semantic,VGG19,VGG19 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg11_bn,classification,imagenet,vgg11_bn,Convolutional,Semantic,VGG11-BatchNorm,VGG11-BatchNorm trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg13_bn,classification,imagenet,vgg13_bn,Convolutional,Semantic,VGG13-BatchNorm,VGG13-BatchNorm trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg16_bn,classification,imagenet,vgg16_bn,Convolutional,Semantic,VGG16-BatchNorm,VGG16-BatchNorm trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg19_bn,classification,imagenet,vgg19_bn,Convolutional,Semantic,VGG19-BatchNorm,VGG19-BatchNorm trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet18,classification,imagenet,resnet18,Convolutional,Semantic,ResNet18,ResNet18 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet34,classification,imagenet,resnet34,Convolutional,Semantic,ResNet34,ResNet34 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet50,classification,imagenet,resnet50,Convolutional,Semantic,ResNet50,ResNet50 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet101,classification,imagenet,resnet101,Convolutional,Semantic,ResNet101,ResNet101 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet152,classification,imagenet,resnet152,Convolutional,Semantic,ResNet152,ResNet152 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
squeezenet1_0,classification,imagenet,squeezenet1_0,Convolutional,Semantic,SqueezeNet1.0,SqueezeNet1.0 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
squeezenet1_1,classification,imagenet,squeezenet1_1,Convolutional,Semantic,SqueezeNet1.1,SqueezeNet1.1 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet121,classification,imagenet,densenet121,Convolutional,Semantic,DenseNet121,DenseNet121 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet161,classification,imagenet,densenet161,Convolutional,Semantic,DenseNet161,DenseNet161 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet169,classification,imagenet,densenet169,Convolutional,Semantic,DenseNet169,DenseNet169 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet201,classification,imagenet,densenet201,Convolutional,Semantic,DenseNet201,DenseNet201 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
googlenet,classification,imagenet,googlenet,Convolutional,Semantic,GoogleNet,GoogleNet trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
shufflenet_v2_x0_5,classification,imagenet,shufflenet_v2_x0_5,Convolutional,Semantic,ShuffleNet-V2-x0.5,ShuffleNet-V2-x0.5 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
shufflenet_v2_x1_0,classification,imagenet,shufflenet_v2_x1_0,Convolutional,Semantic,ShuffleNet-V2-x1.0,ShuffleNet-V2-x1.0 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
mobilenet_v2,classification,imagenet,mobilenet_v2,Convolutional,Semantic,MobileNet-V2,MobileNet-V2 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnext50_32x4d,classification,imagenet,resnext50_32x4d,Convolutional,Semantic,ResNext50-32x4D,ResNext50-32x4D trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnext101_32x8d,classification,imagenet,resnext101_32x8d,Convolutional,Semantic,ResNext50-32x8D,ResNext50-32x8D trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
wide_resnet50_2,classification,imagenet,wide_resnet50_2,Convolutional,Semantic,Wide-ResNet50,Wide-ResNet50 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
wide_resnet101_2,classification,imagenet,wide_resnet101_2,Convolutional,Semantic,Wide-ResNet101,Wide-ResNet101 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
mnasnet0_5,classification,imagenet,mnasnet0_5,Convolutional,Semantic,MNASNet0.5,MNASNet0.5 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
mnasnet1_0,classification,imagenet,mnasnet1_0,Convolutional,Semantic,MNASNet1.0,MNASNet1.0 trained on image classification with the ImageNet dataset.,torchvision,pytorch.org/docs/stable/torchvision/models.html,
alexnet,random,,alexnet,Convolutional,Semantic,AlexNet,"AlexNet randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg11,random,,vgg11,Convolutional,Semantic,VGG11,"VGG11 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg13,random,,vgg13,Convolutional,Semantic,VGG13,"VGG13 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg16,random,,vgg16,Convolutional,Semantic,VGG16,"VGG16 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg19,random,,vgg19,Convolutional,Semantic,VGG19,"VGG19 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg11_bn,random,,vgg11_bn,Convolutional,Semantic,VGG11-BatchNorm,"VGG11-BatchNorm randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg13_bn,random,,vgg13_bn,Convolutional,Semantic,VGG13-BatchNorm,"VGG13-BatchNorm randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg16_bn,random,,vgg16_bn,Convolutional,Semantic,VGG16-BatchNorm,"VGG16-BatchNorm randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
vgg19_bn,random,,vgg19_bn,Convolutional,Semantic,VGG19-BatchNorm,"VGG19-BatchNorm randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet18,random,,resnet18,Convolutional,Semantic,ResNet18,"ResNet18 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet34,random,,resnet34,Convolutional,Semantic,ResNet34,"ResNet34 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet50,random,,resnet50,Convolutional,Semantic,ResNet50,"ResNet50 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet101,random,,resnet101,Convolutional,Semantic,ResNet101,"ResNet101 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnet152,random,,resnet152,Convolutional,Semantic,ResNet152,"ResNet152 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
squeezenet1_0,random,,squeezenet1_0,Convolutional,Semantic,SqueezeNet1.0,"SqueezeNet1.0 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
squeezenet1_1,random,,squeezenet1_1,Convolutional,Semantic,SqueezeNet1.1,"SqueezeNet1.1 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet121,random,,densenet121,Convolutional,Semantic,DenseNet121,"DenseNet121 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet161,random,,densenet161,Convolutional,Semantic,DenseNet161,"DenseNet161 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet169,random,,densenet169,Convolutional,Semantic,DenseNet169,"DenseNet169 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
densenet201,random,,densenet201,Convolutional,Semantic,DenseNet201,"DenseNet201 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
googlenet,random,,googlenet,Convolutional,Semantic,GoogleNet,"GoogleNet randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
shufflenet_v2_x0_5,random,,shufflenet_v2_x0_5,Convolutional,Semantic,ShuffleNet-V2-x0.5,"ShuffleNet-V2-x0.5 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
shufflenet_v2_x1_0,random,,shufflenet_v2_x1_0,Convolutional,Semantic,ShuffleNet-V2-x1.0,"ShuffleNet-V2-x1.0 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
mobilenet_v2,random,,mobilenet_v2,Convolutional,Semantic,MobileNet-V2,"MobileNet-V2 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnext50_32x4d,random,,resnext50_32x4d,Convolutional,Semantic,ResNext50-32x4D,"ResNext50-32x4D randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
resnext101_32x8d,random,,resnext101_32x8d,Convolutional,Semantic,ResNext50-32x8D,"ResNext50-32x8D randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
wide_resnet50_2,random,,wide_resnet50_2,Convolutional,Semantic,Wide-ResNet50,"Wide-ResNet50 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
wide_resnet101_2,random,,wide_resnet101_2,Convolutional,Semantic,Wide-ResNet101,"Wide-ResNet101 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
mnasnet0_5,random,,mnasnet0_5,Convolutional,Semantic,MNASNet0.5,"MNASNet0.5 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
mnasnet1_0,random,,mnasnet1_0,Convolutional,Semantic,MNASNet1.0,"MNASNet1.0 randomly initialized, with no training.",torchvision,pytorch.org/docs/stable/torchvision/models.html,
autoencoding,taskonomy,taskonomy,resnet50,Convolutional,2D,Autoencoder,Image compression and decompression,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
class_object,taskonomy,taskonomy,resnet50,Convolutional,Semantic,Object Classification,1000-way object classification (via knowledge distillation from ImageNet).,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
class_scene,taskonomy,taskonomy,resnet50,Convolutional,Semantic,Scene Classification,Scene Classification (via knowledge distillation from MIT Places).,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
curvature,taskonomy,taskonomy,resnet50,Convolutional,3D,Curvatures,Magnitude of 3D principal curvatures,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
denoising,taskonomy,taskonomy,resnet50,Convolutional,Other,Denoising,Uncorrupted version of corrupted image.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
depth_euclidean,taskonomy,taskonomy,resnet50,Convolutional,3D,Euclidean Depth,Depth estimation,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
depth_zbuffer,taskonomy,taskonomy,resnet50,Convolutional,3D,Z-Buffer Depth,Depth estimation.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
edge_occlusion,taskonomy,taskonomy,resnet50,Convolutional,3D,Occlusion Edges,Edges which include parts of the scene.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
edge_texture,taskonomy,taskonomy,resnet50,Convolutional,2D,Texture Edges,Edges computed from RGB only (texture edges).,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
egomotion,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Egomotion,Odometry (camera poses) given three input images.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
fixated_pose,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Camera Pose (Fixated),Relative camera pose with matching optical centers.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
inpainting,taskonomy,taskonomy,resnet50,Convolutional,2D,Inpainting,Filling in masked center of image.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
jigsaw,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Jigsaw,Putting scrambled image pieces back together.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
keypoints2d,taskonomy,taskonomy,resnet50,Convolutional,2D,2D Keypoints,Keypoint estimation from RGB-only (texture features).,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
keypoints3d,taskonomy,taskonomy,resnet50,Convolutional,3D,3D Keypoints,3D Keypoint estimation from underlying scene 3D.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
nonfixated_pose,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Camera Pose (Nonfixated),Relative camera pose with distinct optical centers.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
normal,taskonomy,taskonomy,resnet50,Convolutional,3D,Surface Normals,Pixel-wise surface normals.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
point_matching,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Point Matching,Classifying if centers of two images match or not.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
reshading,taskonomy,taskonomy,resnet50,Convolutional,3D,Reshading,Reshading with new lighting placed at camera location.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
room_layout,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Room Layout,Orientation and aspect ratio of cubic room layout.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
segment_semantic,taskonomy,taskonomy,resnet50,Convolutional,Semantic,Semantic Segmentation,Pixel-wise semantic labeling (via knowledge distillation from MS COCO).,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
segment_unsup25d,taskonomy,taskonomy,resnet50,Convolutional,3D,Unsupervised 2.5D Segmentation,Segmentation (graph cut approximation) on RGB-D-Normals-Curvature image.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
segment_unsup2d,taskonomy,taskonomy,resnet50,Convolutional,2D,Unsupervised 2D Segmentation,Segmentation (graph cut approximation) on RGB.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
vanishing_point,taskonomy,taskonomy,resnet50,Convolutional,Geometric,Vanishing Point,Three Manhattan-world vanishing points.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
random_weights,taskonomy,,resnet50,Convolutional,Random,Random Weights,Taskonomy architecture randomly initialized.,taskonomy,github.com/alexsax/midlevel-reps/tree/visualpriors,
botnet26t_256,classification,imagenet,botnet26t_256,Transformer,Semantic,BotNet-26T,BotNet-26T trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
cait_s24_224,classification,imagenet,cait_s24_224,Transformer,Semantic,CaiT-S24,CaiT-S24 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
cait_xxs24_224,classification,imagenet,cait_xxs24_224,Transformer,Semantic,CaiT-XXS24,CaiT-XXS24 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
coat_lite_tiny,classification,imagenet,coat_lite_tiny,Transformer,Semantic,CoaT-Lite-Tiny,CoaT-Lite-Tiny trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
coat_lite_small,classification,imagenet,coat_lite_small,Transformer,Semantic,CoaT-Lite-Small,CoaT-Lite-Small trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
coat_mini,classification,imagenet,coat_mini,Transformer,Semantic,CoaT-Mini,CoaT-Mini trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convit_base,classification,imagenet,convit_base,Hybrid,Semantic,ConViT-B,ConViT-B trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convit_small,classification,imagenet,convit_small,Hybrid,Semantic,ConViT-S,ConViT-S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convit_tiny,classification,imagenet,convit_tiny,Hybrid,Semantic,ConViT-T,ConViT-T trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convmixer_768_32,classification,imagenet,convmixer_768_32,Hybrid,Semantic,ConvMixer-768-32,ConvMixer-768-32 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convnext_base,classification,imagenet,convnext_base,Convolutional,Semantic,ConvNext-B,ConvNext-B trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convnext_large,classification,imagenet,convnext_large,Convolutional,Semantic,ConvNext-L,ConvNext-L trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convnext_small,classification,imagenet,convnext_small,Convolutional,Semantic,ConvNext-S,ConvNext-S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
crossvit_base_240,classification,imagenet,crossvit_base_240,Transformer,Semantic,CrossViT-B,CrossViT-B trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
crossvit_tiny_240,classification,imagenet,crossvit_tiny_240,Transformer,Semantic,CrossViT-T,CrossViT-T trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
deit_base_patch16_224,classification,imagenet,deit_base_patch16_224,Transformer,Semantic,DeiT-B-P16-224,DeiT-B-P16-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
deit_small_patch16_224,classification,imagenet,deit_small_patch16_224,Transformer,Semantic,DeiT-S-P16-224,DeiT-S-P16-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
deit_tiny_patch16_224,classification,imagenet,deit_tiny_patch16_224,Transformer,Semantic,DeiT-T-P16-224,DeiT-T-P16-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
cspdarknet53,classification,imagenet,cspdarknet53,Convolutional,Semantic,CSP-DarkNet53,CSP-DarkNet53 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
cspresnet50,classification,imagenet,cspresnet50,Convolutional,Semantic,CSP-ResNet50,CSP-ResNet50 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
dla34,classification,imagenet,dla34,Convolutional,Semantic,DLA34,DLA34 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
dla169,classification,imagenet,dla169,Convolutional,Semantic,DLA169,DLA169 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
eca_nfnet_l0,classification,imagenet,eca_nfnet_l0,Convolutional,Semantic,ECA-NFNeT-L0,ECA-NFNeT-L0 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
eca_nfnet_l1,classification,imagenet,eca_nfnet_l1,Convolutional,Semantic,ECA-NFNeT-L1,ECA-NFNeT-L1 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ecaresnet50d,classification,imagenet,ecaresnet50d,Convolutional,Semantic,ECA-Resnet50-D,ECA-Resnet50-D trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ecaresnet101d,classification,imagenet,ecaresnet101d,Convolutional,Semantic,ECA-Resnet101-D,ECA-Resnet101-D trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b1,classification,imagenet,efficientnet_b1,Convolutional,Semantic,EfficientNet-B1,EfficientNet-B1 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b3,classification,imagenet,efficientnet_b3,Convolutional,Semantic,EfficientNet-B3,EfficientNet-B3 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b5,classification,imagenet,efficientnet_b5,Convolutional,Semantic,EfficientNet-B5,EfficientNet-B5 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b7,classification,imagenet,efficientnet_b7,Convolutional,Semantic,EfficientNet-B7,EfficientNet-B7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
gcresnet50t,classification,imagenet,gcresnet50t,Convolutional,Semantic,GCResNet50T,GCResNet50T trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
efficientnetv2_rw_s,classification,imagenet,efficientnetv2_rw_s,Convolutional,Semantic,EfficientNet-V2-S,EfficientNet-V2-S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
fbnetc_100,classification,imagenet,fbnetc_100,Convolutional,Semantic,FBNetC100,FBNetC100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
gernet_l,classification,imagenet,gernet_l,Convolutional,Semantic,GerNet-L,GerNet-L trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
gernet_s,classification,imagenet,gernet_s,Convolutional,Semantic,GerNet-S,GerNet-S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ghostnet_100,classification,imagenet,ghostnet_100,Convolutional,Semantic,GhostNet100,GhostNet100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
gmixer_24_224,classification,imagenet,gmixer_24_224,Convolutional,Semantic,GMixer-24,GMixer-24 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
gmlp_s16_224,classification,imagenet,gmlp_s16_224,Convolutional,Semantic,GMLP-S16,GMLP-S16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
halonet26t,classification,imagenet,halonet26t,Convolutional,Semantic,HaloNet-26T,HaloNet-26T trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
hardcorenas_a,classification,imagenet,hardcorenas_a,Convolutional,Semantic,HardCoreNAS-A,HardCoreNAS-A trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
hardcorenas_f,classification,imagenet,hardcorenas_f,Convolutional,Semantic,HardCoreNAS-F,HardCoreNAS-F trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
hrnet_w18,classification,imagenet,hrnet_w18,Convolutional,Semantic,HRNet-W18,HRNet-W18 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
hrnet_w64,classification,imagenet,hrnet_w64,Convolutional,Semantic,HRNet-W64,HRNet-W64 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
jx_nest_base,classification,imagenet,jx_nest_base,Transformer,Semantic,JX-NesT-Base,JX-NesT-Base trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
jx_nest_small,classification,imagenet,jx_nest_small,Transformer,Semantic,JX-NesT-Small,JX-NesT-Small trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
jx_nest_tiny,classification,imagenet,jx_nest_tiny,Transformer,Semantic,JX-NesT-Tiny,JX-NesT-Tiny trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
lambda_resnet26t,classification,imagenet,lambda_resnet26t,Convolutional,Semantic,Lambda-ResNet-26T,Lambda-ResNet-26T trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
levit_128,classification,imagenet,levit_128,Transformer,Semantic,LeViT128,LeViT128 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
levit_256,classification,imagenet,levit_256,Transformer,Semantic,LeViT256,LeViT256 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
inception_resnet_v2,classification,imagenet,inception_resnet_v2,Convolutional,Semantic,Inception-Resnet-V2,Inception-Resnet-V2 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
inception_v3,classification,imagenet,inception_v3,Convolutional,Semantic,Inception-V3,Inception-V3 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
inception_v4,classification,imagenet,inception_v4,Convolutional,Semantic,Inception-V4,Inception-V4 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mixer_b16_224,classification,imagenet,mixer_b16_224,MLP-Mixer,Semantic,MLP-Mixer-B16,MLP-Mixer-B16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mixer_l16_224,classification,imagenet,mixer_l16_224,MLP-Mixer,Semantic,MLP-Mixer-L16,MLP-Mixer-L16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mixnet_l,classification,imagenet,mixnet_l,Convolutional,Semantic,MixNet-L,MixNet-L trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mixnet_s,classification,imagenet,mixnet_s,Convolutional,Semantic,MixNet-S,MixNet-S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mnasnet_100,classification,imagenet,mnasnet_100,Convolutional,Semantic,MNASNet100,MNASNet100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mnasnet_100,classification,imagenet,mnasnet_100,Convolutional,Semantic,MNASNet100,MNASNet100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mobilenetv3_large_100,classification,imagenet,mobilenetv3_large_100,Convolutional,Semantic,MobileNet-V3-Large,MobileNet-V3-Large trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mobilenetv3_rw,classification,imagenet,mobilenetv3_rw,Convolutional,Semantic,MobileNet-V3,MobileNet-V3 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mobilevit_s,classification,imagenet,mobilevit_s,Transformer,Semantic,MobileViT-S,MobileViT-S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
nasnetalarge,classification,imagenet,nasnetalarge,Convolutional,Semantic,NASNet-A-Large,NASNet-A-Large trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
nf_resnet50,classification,imagenet,nf_resnet50,Convolutional,Semantic,NF-ResNet50,NF-ResNet50 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
nfnet_l0,classification,imagenet,nfnet_l0,Convolutional,Semantic,NF-Net-L0,NF-Net-L0 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
pit_b_224,classification,imagenet,pit_b_224,Transformer,Semantic,PiT-B-224,PiT-B-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
pit_s_224,classification,imagenet,pit_s_224,Transformer,Semantic,PiT-S-224,PiT-S-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
pit_ti_224,classification,imagenet,pit_ti_224,Transformer,Semantic,PiT-T-224,PiT-T-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
pnasnet5large,classification,imagenet,pnasnet5large,Convolutional,Semantic,PNASNet-5-Large,PNASNet-5-Large trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
poolformer_s12,classification,imagenet,poolformer_s12,Transformer,Semantic,PoolFormer-S12,PoolFormer-S12 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
poolformer_s36,classification,imagenet,poolformer_s36,Transformer,Semantic,PoolFormer-S36,PoolFormer-S36 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
poolformer_m36,classification,imagenet,poolformer_m36,Transformer,Semantic,PoolFormer-M36,PoolFormer-M36 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
pit_ti_224,classification,imagenet,pit_ti_224,Transformer,Semantic,PiT-T-224,PiT-T-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
regnetx_064,classification,imagenet,regnetx_064,Convolutional,Semantic,RegNetX-64,RegNetX-64 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
regnety_064,classification,imagenet,regnety_064,Convolutional,Semantic,RegNetY-64,RegNetY-64 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
repvgg_b1,classification,imagenet,repvgg_b1,Convolutional,Semantic,RepVGG-B1,RepVGG-B1 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
repvgg_b1g4,classification,imagenet,repvgg_b1g4,Convolutional,Semantic,RepVGG-B1G4,RepVGG-B1G4 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
res2net50_26w_4s,classification,imagenet,res2net50_26w_4s,Convolutional,Semantic,Res2Net50-26W-4S,Res2Net50-26W-4S trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_12_224,classification,imagenet,resmlp_12_224,MLP-Mixer,Semantic,ResMLP-12,ResMLP-12 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_24_224,classification,imagenet,resmlp_24_224,MLP-Mixer,Semantic,ResMLP-24,ResMLP-24 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_36_224,classification,imagenet,resmlp_36_224,MLP-Mixer,Semantic,ResMLP-36,ResMLP-36 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_big_24_224,classification,imagenet,resmlp_big_24_224,MLP-Mixer,Semantic,ResMLP-Big-24,ResMLP-Big-24 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnest50d,classification,imagenet,resnest50d,Convolutional,Semantic,ResNest50D,ResNest50D trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetrs50,classification,imagenet,resnetrs50,Convolutional,Semantic,ResNetRS50,ResNetRS50 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
rexnet_100,classification,imagenet,rexnet_100,Convolutional,Semantic,RexNet100,RexNet100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
selecsls60,classification,imagenet,selecsls60,Convolutional,Semantic,SelecSLS60,SelecSLS60 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
semnasnet_100,classification,imagenet,semnasnet_100,Convolutional,Semantic,SemNASNet100,SemNASNet100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
seresnet50,classification,imagenet,seresnet50,Convolutional,Semantic,SEResNet50,SEResNet50 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
seresnext50_32x4d,classification,imagenet,seresnext50_32x4d,Convolutional,Semantic,SEResNext50-32x4D,SEResNext50-32x4D trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
skresnet18,classification,imagenet,skresnet18,Convolutional,Semantic,SKResNet18,SKResNet18 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
skresnext50_32x4d,classification,imagenet,skresnext50_32x4d,Convolutional,Semantic,SKResNext50-32x4D,SKResNext50-32x4D trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
spnasnet_100,classification,imagenet,spnasnet_100,Convolutional,Semantic,SPNasNet100,SPNasNet100 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swin_base_patch4_window7_224,classification,imagenet,swin_base_patch4_window7_224,Transformer,Semantic,Swin-B-P4-W7,Swin-B-P4-W7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swin_large_patch4_window7_224,classification,imagenet,swin_large_patch4_window7_224,Transformer,Semantic,Swin-L-P4-W7,Swin-L-P4-W7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swin_small_patch4_window7_224,classification,imagenet,swin_small_patch4_window7_224,Transformer,Semantic,Swin-S-P4-W7,Swin-S-P4-W7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swin_tiny_patch4_window7_224,classification,imagenet,swin_tiny_patch4_window7_224,Transformer,Semantic,Swin-T-P4-W7,Swin-T-P4-W7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b0,classification,imagenet,tf_efficientnet_b0,Convolutional,Semantic,TF-EfficientNet-B0,TF-EfficientNet-B0 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b1,classification,imagenet,tf_efficientnet_b1,Convolutional,Semantic,TF-EfficientNet-B1,TF-EfficientNet-B1 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b2,classification,imagenet,tf_efficientnet_b2,Convolutional,Semantic,TF-EfficientNet-B2,TF-EfficientNet-B2 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b3,classification,imagenet,tf_efficientnet_b3,Convolutional,Semantic,TF-EfficientNet-B3,TF-EfficientNet-B3 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b4,classification,imagenet,tf_efficientnet_b4,Convolutional,Semantic,TF-EfficientNet-B4,TF-EfficientNet-B4 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b5,classification,imagenet,tf_efficientnet_b5,Convolutional,Semantic,TF-EfficientNet-B5,TF-EfficientNet-B5 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b6,classification,imagenet,tf_efficientnet_b6,Convolutional,Semantic,TF-EfficientNet-B6,TF-EfficientNet-B6 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b7,classification,imagenet,tf_efficientnet_b7,Convolutional,Semantic,TF-EfficientNet-B7,TF-EfficientNet-B7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tnt_s_patch16_224,classification,imagenet,tnt_s_patch16_224,Transformer,Semantic,TnT-P16-224,TnT-P16-224 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tresnet_l,classification,imagenet,tresnet_l,Convolutional,Semantic,TResNet-L,TResNet-L trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
twins_pcpvt_base,classification,imagenet,twins_pcpvt_base,Transformer,Semantic,Twins-PCPVT-B,Twins-PCPVT-B trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
twins_svt_base,classification,imagenet,twins_svt_base,Transformer,Semantic,Twins-SVT-B,Twins-SVT-B trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
visformer_small,classification,imagenet,visformer_small,Transformer,Semantic,Visformer,Visformer trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_large_patch16_224,classification,imagenet,vit_large_patch16_224,Transformer,Semantic,ViT-L-P16,ViT-L-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch16_224,classification,imagenet,vit_small_patch16_224,Transformer,Semantic,ViT-S-P16,ViT-S-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_tiny_patch16_224,classification,imagenet,vit_tiny_patch16_224,Transformer,Semantic,ViT-T-P16,ViT-T-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch16_224,classification,imagenet,vit_base_patch16_224,Transformer,Semantic,ViT-B-P16,ViT-B-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch32_224,classification,imagenet,vit_base_patch32_224,Transformer,Semantic,ViT-B-P32,ViT-B-P32 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_large_patch32_224,classification,imagenet,vit_large_patch32_224,Transformer,Semantic,ViT-L-P32,ViT-L-P32 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch32_224,classification,imagenet,vit_small_patch32_224,Transformer,Semantic,ViT-S-P32,ViT-S-P32 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
volo_d1_224,classification,imagenet,volo_d1_224,Transformer,Semantic,VoLo-D1,VoLo-D1 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
volo_d3_224,classification,imagenet,volo_d3_224,Transformer,Semantic,VoLo-D3,VoLo-D3 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
volo_d5_224,classification,imagenet,volo_d5_224,Transformer,Semantic,VoLo-D5,VoLo-D5 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xception,classification,imagenet,xception,Convolutional,Semantic,XCeption,XCeption trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xception65,classification,imagenet,xception65,Convolutional,Semantic,XCeption65,XCeption65 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xcit_nano_12_p8_224,classification,imagenet,xcit_nano_12_p8_224,Transformer,Semantic,XCIT-N-12-P8,XCIT-N-12-P8 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xcit_small_12_p8_224,classification,imagenet,xcit_small_12_p8_224,Transformer,Semantic,XCIT-S-12-P8,XCIT-S-12-P8 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xcit_medium_24_p8_224,classification,imagenet,xcit_medium_24_p8_224,Transformer,Semantic,XCIT-M-24-P8,XCIT-M-24-P8 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xcit_nano_12_p16_224,classification,imagenet,xcit_nano_12_p16_224,Transformer,Semantic,XCIT-N-12-P16,XCIT-N-12-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xcit_small_12_p16_224,classification,imagenet,xcit_small_12_p16_224,Transformer,Semantic,XCIT-S-12-P16,XCIT-S-12-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
xcit_medium_24_p16_224,classification,imagenet,xcit_medium_24_p16_224,Transformer,Semantic,XCIT-M-24-P16,XCIT-M-24-P16 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
botnet26t_256,random,,botnet26t_256,Transformer,Semantic,BotNet-26T,"BotNet-26T randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
cait_s24_224,random,,cait_s24_224,Transformer,Semantic,CaiT-S24,"CaiT-S24 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
cait_xxs24_224,random,,cait_xxs24_224,Transformer,Semantic,CaiT-XXS24,"CaiT-XXS24 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
coat_lite_tiny,random,,coat_lite_tiny,Transformer,Semantic,CoaT-Lite-Tiny,"CoaT-Lite-Tiny randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
coat_lite_small,random,,coat_lite_small,Transformer,Semantic,CoaT-Lite-Small,"CoaT-Lite-Small randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
coat_mini,random,,coat_mini,Transformer,Semantic,CoaT-Mini,"CoaT-Mini randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convit_base,random,,convit_base,Hybrid,Semantic,ConViT-B,"ConViT-B randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convit_small,random,,convit_small,Hybrid,Semantic,ConViT-S,"ConViT-S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convit_tiny,random,,convit_tiny,Hybrid,Semantic,ConViT-T,"ConViT-T randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convmixer_768_32,random,,convmixer_768_32,Hybrid,Semantic,ConvMixer-768-32,"ConvMixer-768-32 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convnext_base,random,,convnext_base,Convolutional,Semantic,ConvNext-B,"ConvNext-B randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convnext_large,random,,convnext_large,Convolutional,Semantic,ConvNext-L,"ConvNext-L randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
convnext_small,random,,convnext_small,Convolutional,Semantic,ConvNext-S,"ConvNext-S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
crossvit_base_240,random,,crossvit_base_240,Transformer,Semantic,CrossViT-B,"CrossViT-B randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
crossvit_tiny_240,random,,crossvit_tiny_240,Transformer,Semantic,CrossViT-T,"CrossViT-T randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
deit_base_patch16_224,random,,deit_base_patch16_224,Transformer,Semantic,DeiT-B-P16-224,"DeiT-B-P16-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
deit_small_patch16_224,random,,deit_small_patch16_224,Transformer,Semantic,DeiT-S-P16-224,"DeiT-S-P16-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
deit_tiny_patch16_224,random,,deit_tiny_patch16_224,Transformer,Semantic,DeiT-T-P16-224,"DeiT-T-P16-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
cspdarknet53,random,,cspdarknet53,Convolutional,Semantic,CSP-DarkNet53,"CSP-DarkNet53 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
cspresnet50,random,,cspresnet50,Convolutional,Semantic,CSP-ResNet50,"CSP-ResNet50 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
dla34,random,,dla34,Convolutional,Semantic,DLA34,"DLA34 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
dla169,random,,dla169,Convolutional,Semantic,DLA169,"DLA169 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
eca_nfnet_l0,random,,eca_nfnet_l0,Convolutional,Semantic,ECA-NFNeT-L0,"ECA-NFNeT-L0 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
eca_nfnet_l1,random,,eca_nfnet_l1,Convolutional,Semantic,ECA-NFNeT-L1,"ECA-NFNeT-L1 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
ecaresnet50d,random,,ecaresnet50d,Convolutional,Semantic,ECA-Resnet50-D,"ECA-Resnet50-D randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
ecaresnet101d,random,,ecaresnet101d,Convolutional,Semantic,ECA-Resnet101-D,"ECA-Resnet101-D randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b1,random,,efficientnet_b1,Convolutional,Semantic,EfficientNet-B1,"EfficientNet-B1 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b3,random,,efficientnet_b3,Convolutional,Semantic,EfficientNet-B3,"EfficientNet-B3 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b5,random,,efficientnet_b5,Convolutional,Semantic,EfficientNet-B5,"EfficientNet-B5 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
efficientnet_b7,random,,efficientnet_b7,Convolutional,Semantic,EfficientNet-B7,"EfficientNet-B7 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
gcresnet50t,random,,gcresnet50t,Convolutional,Semantic,GCResNet50T,"GCResNet50T randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
efficientnetv2_rw_s,random,,efficientnetv2_rw_s,Convolutional,Semantic,EfficientNet-V2-S,"EfficientNet-V2-S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
fbnetc_100,random,,fbnetc_100,Convolutional,Semantic,FBNetC100,"FBNetC100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
gernet_l,random,,gernet_l,Convolutional,Semantic,GerNet-L,"GerNet-L randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
gernet_s,random,,gernet_s,Convolutional,Semantic,GerNet-S,"GerNet-S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
ghostnet_100,random,,ghostnet_100,Convolutional,Semantic,GhostNet100,"GhostNet100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
gmixer_24_224,random,,gmixer_24_224,Convolutional,Semantic,GMixer-24,"GMixer-24 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
gmlp_s16_224,random,,gmlp_s16_224,Convolutional,Semantic,GMLP-S16,"GMLP-S16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
halonet26t,random,,halonet26t,Convolutional,Semantic,HaloNet-26T,"HaloNet-26T randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
hardcorenas_a,random,,hardcorenas_a,Convolutional,Semantic,HardCoreNAS-A,"HardCoreNAS-A randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
hardcorenas_f,random,,hardcorenas_f,Convolutional,Semantic,HardCoreNAS-F,"HardCoreNAS-F randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
hrnet_w18,random,,hrnet_w18,Convolutional,Semantic,HRNet-W18,"HRNet-W18 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
hrnet_w64,random,,hrnet_w64,Convolutional,Semantic,HRNet-W64,"HRNet-W64 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
jx_nest_base,random,,jx_nest_base,Transformer,Semantic,JX-NesT-Base,"JX-NesT-Base randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
jx_nest_small,random,,jx_nest_small,Transformer,Semantic,JX-NesT-Small,"JX-NesT-Small randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
jx_nest_tiny,random,,jx_nest_tiny,Transformer,Semantic,JX-NesT-Tiny,"JX-NesT-Tiny randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
lambda_resnet26t,random,,lambda_resnet26t,Convolutional,Semantic,Lambda-ResNet-26T,"Lambda-ResNet-26T randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
levit_128,random,,levit_128,Transformer,Semantic,LeViT128,"LeViT128 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
levit_256,random,,levit_256,Transformer,Semantic,LeViT256,"LeViT256 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
inception_resnet_v2,random,,inception_resnet_v2,Convolutional,Semantic,Inception-Resnet-V2,"Inception-Resnet-V2 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
inception_v3,random,,inception_v3,Convolutional,Semantic,Inception-V3,"Inception-V3 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
inception_v4,random,,inception_v4,Convolutional,Semantic,Inception-V4,"Inception-V4 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mixer_b16_224,random,,mixer_b16_224,MLP-Mixer,Semantic,MLP-Mixer-B16,"MLP-Mixer-B16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mixer_l16_224,random,,mixer_l16_224,MLP-Mixer,Semantic,MLP-Mixer-L16,"MLP-Mixer-L16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mixnet_l,random,,mixnet_l,Convolutional,Semantic,MixNet-L,"MixNet-L randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mixnet_s,random,,mixnet_s,Convolutional,Semantic,MixNet-S,"MixNet-S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mnasnet_100,random,,mnasnet_100,Convolutional,Semantic,MNASNet100,"MNASNet100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mnasnet_100,random,,mnasnet_100,Convolutional,Semantic,MNASNet100,"MNASNet100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mobilenetv3_large_100,random,,mobilenetv3_large_100,Convolutional,Semantic,MobileNet-V3-Large,"MobileNet-V3-Large randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mobilenetv3_rw,random,,mobilenetv3_rw,Convolutional,Semantic,MobileNet-V3,"MobileNet-V3 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
mobilevit_s,random,,mobilevit_s,Transformer,Semantic,MobileViT-S,"MobileViT-S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
nasnetalarge,random,,nasnetalarge,Convolutional,Semantic,NASNet-A-Large,"NASNet-A-Large randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
nf_resnet50,random,,nf_resnet50,Convolutional,Semantic,NF-ResNet50,"NF-ResNet50 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
nfnet_l0,random,,nfnet_l0,Convolutional,Semantic,NF-Net-L0,"NF-Net-L0 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
pit_b_224,random,,pit_b_224,Transformer,Semantic,PiT-B-224,"PiT-B-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
pit_s_224,random,,pit_s_224,Transformer,Semantic,PiT-S-224,"PiT-S-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
pit_ti_224,random,,pit_ti_224,Transformer,Semantic,PiT-T-224,"PiT-T-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
pnasnet5large,random,,pnasnet5large,Convolutional,Semantic,PNASNet-5-Large,"PNASNet-5-Large randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
poolformer_s12,random,,poolformer_s12,Transformer,Semantic,PoolFormer-S12,"PoolFormer-S12 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
poolformer_s36,random,,poolformer_s36,Transformer,Semantic,PoolFormer-S36,"PoolFormer-S36 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
poolformer_m36,random,,poolformer_m36,Transformer,Semantic,PoolFormer-M36,"PoolFormer-M36 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
pit_ti_224,random,,pit_ti_224,Transformer,Semantic,PiT-T-224,"PiT-T-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
regnetx_064,random,,regnetx_064,Convolutional,Semantic,RegNetX-64,"RegNetX-64 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
regnety_064,random,,regnety_064,Convolutional,Semantic,RegNetY-64,"RegNetY-64 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
repvgg_b1,random,,repvgg_b1,Convolutional,Semantic,RepVGG-B1,"RepVGG-B1 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
repvgg_b1g4,random,,repvgg_b1g4,Convolutional,Semantic,RepVGG-B1G4,"RepVGG-B1G4 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
res2net50_26w_4s,random,,res2net50_26w_4s,Convolutional,Semantic,Res2Net50-26W-4S,"Res2Net50-26W-4S randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_12_224,random,,resmlp_12_224,MLP-Mixer,Semantic,ResMLP-12,"ResMLP-12 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_24_224,random,,resmlp_24_224,MLP-Mixer,Semantic,ResMLP-24,"ResMLP-24 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_36_224,random,,resmlp_36_224,MLP-Mixer,Semantic,ResMLP-36,"ResMLP-36 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_big_24_224,random,,resmlp_big_24_224,MLP-Mixer,Semantic,ResMLP-Big-24,"ResMLP-Big-24 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
resnest50d,random,,resnest50d,Convolutional,Semantic,ResNest50D,"ResNest50D randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
resnetrs50,random,,resnetrs50,Convolutional,Semantic,ResNetRS50,"ResNetRS50 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
rexnet_100,random,,rexnet_100,Convolutional,Semantic,RexNet100,"RexNet100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
selecsls60,random,,selecsls60,Convolutional,Semantic,SelecSLS60,"SelecSLS60 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
semnasnet_100,random,,semnasnet_100,Convolutional,Semantic,SemNASNet100,"SemNASNet100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
seresnet50,random,,seresnet50,Convolutional,Semantic,SEResNet50,"SEResNet50 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
seresnext50_32x4d,random,,seresnext50_32x4d,Convolutional,Semantic,SEResNext50-32x4D,"SEResNext50-32x4D randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
skresnet18,random,,skresnet18,Convolutional,Semantic,SKResNet18,"SKResNet18 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
skresnext50_32x4d,random,,skresnext50_32x4d,Convolutional,Semantic,SKResNext50-32x4D,"SKResNext50-32x4D randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
spnasnet_100,random,,spnasnet_100,Convolutional,Semantic,SPNasNet100,"SPNasNet100 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
swin_base_patch4_window7_224,random,,swin_base_patch4_window7_224,Transformer,Semantic,Swin-B-P4-W7,"Swin-B-P4-W7 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
swin_large_patch4_window7_224,random,,swin_large_patch4_window7_224,Transformer,Semantic,Swin-L-P4-W7,"Swin-L-P4-W7 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
swin_small_patch4_window7_224,random,,swin_small_patch4_window7_224,Transformer,Semantic,Swin-S-P4-W7,"Swin-S-P4-W7 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
swin_tiny_patch4_window7_224,random,,swin_tiny_patch4_window7_224,Transformer,Semantic,Swin-T-P4-W7,"Swin-T-P4-W7 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b0,random,,tf_efficientnet_b0,Convolutional,Semantic,TF-EfficientNet-B0,"TF-EfficientNet-B0 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b1,random,,tf_efficientnet_b1,Convolutional,Semantic,TF-EfficientNet-B1,"TF-EfficientNet-B1 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b2,random,,tf_efficientnet_b2,Convolutional,Semantic,TF-EfficientNet-B2,"TF-EfficientNet-B2 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b3,random,,tf_efficientnet_b3,Convolutional,Semantic,TF-EfficientNet-B3,"TF-EfficientNet-B3 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b4,random,,tf_efficientnet_b4,Convolutional,Semantic,TF-EfficientNet-B4,"TF-EfficientNet-B4 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b5,random,,tf_efficientnet_b5,Convolutional,Semantic,TF-EfficientNet-B5,"TF-EfficientNet-B5 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b6,random,,tf_efficientnet_b6,Convolutional,Semantic,TF-EfficientNet-B6,"TF-EfficientNet-B6 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b7,random,,tf_efficientnet_b7,Convolutional,Semantic,TF-EfficientNet-B7,"TF-EfficientNet-B7 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tnt_s_patch16_224,random,,tnt_s_patch16_224,Transformer,Semantic,TnT-P16-224,"TnT-P16-224 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
tresnet_l,random,,tresnet_l,Convolutional,Semantic,TResNet-L,"TResNet-L randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
twins_pcpvt_base,random,,twins_pcpvt_base,Transformer,Semantic,Twins-PCPVT-B,"Twins-PCPVT-B randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
twins_svt_base,random,,twins_svt_base,Transformer,Semantic,Twins-SVT-B,"Twins-SVT-B randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
visformer_small,random,,visformer_small,Transformer,Semantic,Visformer,"Visformer randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_large_patch16_224,random,,vit_large_patch16_224,Transformer,Semantic,ViT-L-P16,"ViT-L-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch16_224,random,,vit_small_patch16_224,Transformer,Semantic,ViT-S-P16,"ViT-S-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_tiny_patch16_224,random,,vit_tiny_patch16_224,Transformer,Semantic,ViT-T-P16,"ViT-T-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch16_224,random,,vit_base_patch16_224,Transformer,Semantic,ViT-B-P16,"ViT-B-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch32_224,random,,vit_base_patch32_224,Transformer,Semantic,ViT-B-P32,"ViT-B-P32 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_large_patch32_224,random,,vit_large_patch32_224,Transformer,Semantic,ViT-L-P32,"ViT-L-P32 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch32_224,random,,vit_small_patch32_224,Transformer,Semantic,ViT-S-P32,"ViT-S-P32 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
volo_d1_224,random,,volo_d1_224,Transformer,Semantic,VoLo-D1,"VoLo-D1 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
volo_d3_224,random,,volo_d3_224,Transformer,Semantic,VoLo-D3,"VoLo-D3 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
volo_d5_224,random,,volo_d5_224,Transformer,Semantic,VoLo-D5,"VoLo-D5 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xception,random,,xception,Convolutional,Semantic,XCeption,"XCeption randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xception65,random,,xception65,Convolutional,Semantic,XCeption65,"XCeption65 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xcit_nano_12_p8_224,random,,xcit_nano_12_p8_224,Transformer,Semantic,XCIT-N-12-P8,"XCIT-N-12-P8 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xcit_small_12_p8_224,random,,xcit_small_12_p8_224,Transformer,Semantic,XCIT-S-12-P8,"XCIT-S-12-P8 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xcit_medium_24_p8_224,random,,xcit_medium_24_p8_224,Transformer,Semantic,XCIT-M-24-P8,"XCIT-M-24-P8 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xcit_nano_12_p16_224,random,,xcit_nano_12_p16_224,Transformer,Semantic,XCIT-N-12-P16,"XCIT-N-12-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xcit_small_12_p16_224,random,,xcit_small_12_p16_224,Transformer,Semantic,XCIT-S-12-P16,"XCIT-S-12-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
xcit_medium_24_p16_224,random,,xcit_medium_24_p16_224,Transformer,Semantic,XCIT-M-24-P16,"XCIT-M-24-P16 randomly initialized, with no training.",timm,https://github.com/rwightman/pytorch-image-models/,
RN50,clip,openai400M,ResNet50,Convolutional,Vision-Language,CLiP-ResNet50,"CLiP-ResNet50, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
RN101,clip,openai400M,ResNet101,Convolutional,Vision-Language,CLiP-ResNet101,"CLiP-ResNet101, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
RN50x4,clip,openai400M,ResNet50x4,Convolutional,Vision-Language,CLiP-ResNet50x4,"CLiP-ResNet50x4, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
RN50x16,clip,openai400M,ResNet50x16,Convolutional,Vision-Language,CLiP-ResNet50x16,"CLiP-ResNet50x16, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
RN50x64,clip,openai400M,ResNet50x64,Convolutional,Vision-Language,CLiP-ResNet50x64,"CLiP-ResNet50x64, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
ViT-B/32,clip,openai400M,ViT-B/32,Transformer,Vision-Language,CLiP-ViT-B/32,"CLiP-ViT-B/32, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
ViT-B/16,clip,openai400M,ViT-B/16,Transformer,Vision-Language,CLiP-ViT-B/32,"CLiP-ViT-B/32, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
ViT-L/14,clip,openai400M,ViT-L/14,Transformer,Vision-Language,CLiP-ViT-L/14,"CLiP-ViT-L/14, a hybrid vision-language model.",clip,https://github.com/openai/CLIP,
ResNet50-JigSaw-P100,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-JigSaw-P100,"ResNet50-JigSaw-P100, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/jigsaw_rn50_in1k_ep105_perm2k_jigsaw_8gpu_resnet_17_07_20.db174a43/model_final_checkpoint_phase104.torch
ResNet50-JigSaw-Goyal19,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-JigSaw-Goyal19,"ResNet50-JigSaw-Goyal19, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/converted_vissl_rn50_jigsaw_in1k_goyal19.torch
ResNet50-RotNet,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-RotNet,"ResNet50-RotNet, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/rotnet_rn50_in1k_ep105_rotnet_8gpu_resnet_17_07_20.46bada9f/model_final_checkpoint_phase125.torch
ResNet50-ClusterFit-16K-RotNet,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-ClusterFit-16K-RotNet,"ResNet50-ClusterFit-16K-RotNet, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/converted_vissl_rn50_rotnet_16kclusters_in1k_ep105.torch
ResNet50-NPID-4KNegative,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-NPID-4KNegative,"ResNet50-NPID-4KNegative, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/npid_1node_200ep_4kneg_npid_8gpu_resnet_23_07_20.9eb36512/model_final_checkpoint_phase199.torch
ResNet50-PIRL,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-PIRL,"ResNet50-PIRL, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/pirl_jigsaw_4node_pirl_jigsaw_4node_resnet_22_07_20.34377f59/model_final_checkpoint_phase799.torch
ResNet50-SimCLR,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-SimCLR,"ResNet50-SimCLR, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/simclr_rn50_1000ep_simclr_8node_resnet_16_07_20.afe428c7/model_final_checkpoint_phase999.torch
ResNet50-DeepClusterV2-2x224,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-DeepClusterV2,"ResNet50-DeepClusterV2-2x224, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/deepclusterv2_400ep_2x224_pretrain.pth.tar
ResNet50-DeepClusterV2-2x224+6x96,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-DeepClusterV2,"ResNet50-DeepClusterV2-2x224+6x96, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/deepclusterv2_800ep_pretrain.pth.tar
ResNet50-SwAV-BS4096-2x224,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-SwAV-BS4096,"ResNet50-SwAV-BS4096-2x224, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/swav_in1k_rn50_400ep_swav_8node_resnet_27_07_20.a5990fc9/model_final_checkpoint_phase399.torch
ResNet50-SwAV-BS4096-2x224+6x96,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-SwAV-BS4096,"ResNet50-SwAV-BS4096-2x224+6x96, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/swav_8node_2x224_rn50_in1k_swav_8node_resnet_30_07_20.c8fd7169/model_final_checkpoint_phase399.torch
ResNet50-MoCoV2-BS256,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-MoCoV2-BS256,"ResNet50-MoCoV2-BS256, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/moco_v2_1node_lr.03_step_b32_zero_init/model_final_checkpoint_phase199.torch
ResNet50-BarlowTwins-BS2048,selfsupervised,imagenet,ResNet50,Convolutional,Self-Supervised,ResNet50-BarlowTwins-BS2048,"ResNet50-BarlowTwins-BS2048, a self-supervised representation learner trained on ImageNet.",vissl,https://github.com/facebookresearch/vissl/, https://dl.fbaipublicfiles.com/vissl/model_zoo/barlow_twins/barlow_twins_32gpus_4node_imagenet1k_1000ep_resnet50.torch
dino_vits16,selfsupervised,imagenet,vits16,Transformer,SelfSupervised,Dino-VIT-S16,Dino-VIT-S16 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_vits8,selfsupervised,imagenet,vits8,Transformer,SelfSupervised,Dino-VIT-S8,Dino-VIT-S8 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_vitb16,selfsupervised,imagenet,vitb16,Transformer,SelfSupervised,Dino-VIT-B16,Dino-VIT-B16 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_vitb8,selfsupervised,imagenet,vitb8,Transformer,SelfSupervised,Dino-VIT-B8,Dino-VIT-B8 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_xcit_small_12_p16,selfsupervised,imagenet,xcit_small_12_p16,Transformer,SelfSupervised,Dino-XCIT-S12-P16,Dino-XCIT-S12-P16 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_xcit_small_12_p8,selfsupervised,imagenet,xcit_small_12_p8,Transformer,SelfSupervised,Dino-XCIT-S12-P8,Dino-XCIT-S12-P8 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_xcit_medium_24_p16,selfsupervised,imagenet,xcit_medium_24_p16,Transformer,SelfSupervised,Dino-XCIT-M24-P16,Dino-XCIT-M24-P16 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_xcit_medium_24_p8,selfsupervised,imagenet,xcit_medium_24_p8,Transformer,SelfSupervised,Dino-XCIT-M24-P8,Dino-XCIT-M24-P8 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
dino_resnet50,selfsupervised,imagenet,resnet50,Convolutional,SelfSupervised,Dino-ResNet50,Dino-ResNet50 trained via self supervision with the ImageNet dataset.,dino,https://github.com/facebookresearch/dino,
DPT_Hybrid,monoculardepth,"ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS",DPT_Hybrid,Transformer,MonocularDepth,DPT-Hybrid,"DPT-Hybrid, a monocular depth estimation model.",midas,https://github.com/isl-org/MiDaS,
DPT_Large,monoculardepth,"ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS",DPT_Large,Transformer,MonocularDepth,DPT-Large,"DPT-Large, a monocular depth estimation model.",midas,https://github.com/isl-org/MiDaS,
MiDas,monoculardepth,"ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS",MiDas,Convolutional,MonocularDepth,MiDas,"MiDas, a monocular depth estimation model.",midas,https://github.com/isl-org/MiDaS,
MiDas_small,monoculardepth,"ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS",MiDas_small,Convolutional,MonocularDepth,MiDas-Small,"MiDas-Small, a monocular depth estimation model.",midas,https://github.com/isl-org/MiDaS,
yolov5l,yolo,"coco,voc",yolov5l,Convolutional,Detection,YOLO-V5-L,"YOLO-V5-L, an object detection model.",yolo,https://github.com/ultralytics/yolov5,
yolov5m,yolo,"coco,voc",yolov5m,Convolutional,Detection,YOLO-V5-M,"YOLO-V5-M, an object detection model.",yolo,https://github.com/ultralytics/yolov5,
yolov5n,yolo,"coco,voc",yolov5n,Convolutional,Detection,YOLO-V5-N,"YOLO-V5-N, an object detection model.",yolo,https://github.com/ultralytics/yolov5,
yolov5s,yolo,"coco,voc",yolov5s,Convolutional,Detection,YOLO-V5-S,"YOLO-V5-S, an object detection model.",yolo,https://github.com/ultralytics/yolov5,
yolov5x,yolo,"coco,voc",yolov5x,Convolutional,Detection,YOLO-V5-S,"YOLO-V5-S, an object detection model.",yolo,https://github.com/ultralytics/yolov5,
faster_rcnn_R_50_C4_3x,detection,coco2017,faster_rcnn_R_50_C4_3x,Convolutional,Detection|Segmentation,Faster-RCNN-ResNet50-C4,"Faster-RCNN-ResNet50-C4, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_R_50_C4_3x.yaml
faster_rcnn_R_50_DC5_3x,detection,coco2017,faster_rcnn_R_50_DC5_3x,Convolutional,Detection|Segmentation,Faster-RCNN-ResNet50-DC5,"Faster-RCNN-ResNet50-DC5, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml
faster_rcnn_R_50_FPN_3x,detection,coco2017,faster_rcnn_R_50_FPN_3x,Convolutional,Detection|Segmentation,Faster-RCNN-ResNet50-FPN,"Faster-RCNN-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
faster_rcnn_R_101_C4_3x,detection,coco2017,faster_rcnn_R_101_C4_3x,Convolutional,Detection|Segmentation,Faster-RCNN-ResNet101-C4,"Faster-RCNN-ResNet101-C4, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_R_101_C4_3x.yaml
faster_rcnn_R_101_DC5_3x,detection,coco2017,faster_rcnn_R_101_DC5_3x,Convolutional,Detection|Segmentation,Faster-RCNN-ResNet101-DC5,"Faster-RCNN-ResNet101-DC5, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml
faster_rcnn_R_101_FPN_3x,detection,coco2017,faster_rcnn_R_101_FPN_3x,Convolutional,Detection|Segmentation,Faster-RCNN-ResNet101-FPN,"Faster-RCNN-ResNet101-FPN, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml
faster_rcnn_X_101_32x8d_FPN_3x,detection,coco2017,faster_rcnn_X_101_32x8d_FPN_3x,Convolutional,Detection|Segmentation,Faster-RCNN-X101-FPN,"Faster-RCNN-X101-FPN, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml
retinanet_R_50_FPN_3x,detection,coco2017,retinanet_R_50_FPN_3x,Convolutional,Detection|Segmentation,RetinaNet-ResNet50-FPN,"RetinaNet-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/retinanet_R_50_FPN_3x.yaml
retinanet_R_101_FPN_3x,detection,coco2017,retinanet_R_101_FPN_3x,Convolutional,Detection|Segmentation,RetinaNet-ResNet101-FPN,"RetinaNet-ResNet101-FPN, trained on detection with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Detection/retinanet_R_101_FPN_3x.yaml
mask_rcnn_R_50_C4_3x,segmentation,coco2017,mask_rcnn_R_50_C4_3x,Convolutional,Detection|Segmentation,Mask-RCNN-ResNet50-C4,"Mask-RCNN-ResNet50-C4, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml
mask_rcnn_R_50_DC5_3x,segmentation,coco2017,mask_rcnn_R_50_DC5_3x,Convolutional,Detection|Segmentation,Mask-RCNN-ResNet50-DC5,"Mask-RCNN-ResNet50-DC5, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml
mask_rcnn_R_50_FPN_3x,segmentation,coco2017,mask_rcnn_R_50_FPN_3x,Convolutional,Detection|Segmentation,Mask-RCNN-ResNet50-FPN,"Mask-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml
mask_rcnn_R_101_C4_3x,segmentation,coco2017,mask_rcnn_R_101_C4_3x,Convolutional,Detection|Segmentation,Mask-RCNN-ResNet101-C4,"Mask-RCNN-ResNet101-C4, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml
mask_rcnn_R_101_DC5_3x,segmentation,coco2017,mask_rcnn_R_101_DC5_3x,Convolutional,Detection|Segmentation,Mask-RCNN-ResNet101-DC5,"Mask-RCNN-ResNet101-DC5, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml
mask_rcnn_R_101_FPN_3x,segmentation,coco2017,mask_rcnn_R_101_FPN_3x,Convolutional,Detection|Segmentation,Mask-RCNN-ResNet101-FPN,"Mask-RCNN-ResNet101-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml
mask_rcnn_X_101_32x8d_FPN_3x,segmentation,coco2017,mask_rcnn_X_101_32x8d_FPN_3x,Convolutional,Detection|Segmentation,Mask-RCNN-X101-FPN,"Mask-RCNN-X101-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml
keypoint_rcnn_R_50_FPN_3x,segmentation,coco2017,keypoint_rcnn_R_50_FPN_3x,Convolutional,Detection|Segmentation,Keypoint-RCNN-ResNet50-FPN,"Keypoint-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml
panoptic_fpn_R_50_3x,panoptics,coco2017,panoptic_fpn_R_50_3x,Convolutional,Detection|Segmentation,Panoptic-RCNN-ResNet50-FPN,"Panoptic-RCNN-ResNet50-FPN, trained on panoptics with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml
mask_rcnn_R_50_FPN_1x,segmentation,LVIS,mask_rcnn_R_50_FPN_1x,Convolutional,Detection|Segmentation,LVIS-RCNN-ResNet50-FPN,"LVIS-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,LVISv0.5-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
mask_rcnn_R_101_FPN_1x,segmentation,LVIS,mask_rcnn_R_101_FPN_1x,Convolutional,Detection|Segmentation,LVIS-RCNN-ResNet101-FPN,"LVIS-RCNN-ResNet101-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,LVISv0.5-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml
mask_rcnn_X_101_32x8d_FPN_1x,segmentation,LVIS,mask_rcnn_X_101_32x8d_FPN_1x,Convolutional,Detection|Segmentation,LVIS-RCNN-X101-FPN,"LVIS-RCNN-X101-FPN, trained on segmentation with the CoCo2017 dataset.",detectron,https://github.com/facebookresearch/detectron2/,LVISv0.5-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml
adv_inception_v3,adversarial,imagenet,inception_v3,Convolutional,Semantic,Adversarial-Inception-V3,Adversarial-Inception-V3 trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
beit_base_patch16_224,bert_pretraining,imagenet,beit_base_patch16_224,Transformer,Semantic,BEiT-S-P16,BEiT-S-P16 trained on masked-input-pretrained classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
beit_large_patch16_224,bert_pretraining,imagenet,beit_large_patch16_224,Transformer,Semantic,BEiT-L-P16,BEiT-L-P16 trained on masked-input-pretrained classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetv2_50x1_bitm,big_transfer,big_transfer,resnetv2_50x1,Convolutional,Semantic,ResNetV2-50x1-BitM,ResNetV2-50x1-BitM trained on large dataset pretraining with the BiT-M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetv2_101x3_bitm,big_transfer,big_transfer,resnetv2_101x3,Convolutional,Semantic,ResNetV2-101x3-BitM,ResNetV2-101x3-BitM trained on large dataset pretraining with the BiT-M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetv2_152x4_bitm,big_transfer,big_transfer,resnetv2_152x4,Convolutional,Semantic,ResNetV2-152x4-BitM,ResNetV2-152x4-BitM trained on large dataset pretraining with the BiT-M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetv2_50x1_bitm_in21k,big_transfer,big_transfer,resnetv2_50x1,Convolutional,Semantic,ResNetV2-50x1-BitM-IN21K,ResNetV2-50x1-BitM-IN21K trained on large dataset pretraining with the BiT-M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetv2_101x3_bitm_in21k,big_transfer,big_transfer,resnetv2_101x3,Convolutional,Semantic,ResNetV2-101x3-BitM-IN21K,ResNetV2-101x3-BitM-IN21K trained on large dataset pretraining with the BiT-M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resnetv2_152x4_bitm_in21k,big_transfer,big_transfer,resnetv2_152x4,Convolutional,Semantic,ResNetV2-152x4-BitM-IN21K,ResNetV2-152x4-BitM-IN21K trained on large dataset pretraining with the BiT-M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convnext_base_in22k,classification,imagenet21k,convnext_base,Convolutional,Semantic,ConvNext-Base-IN21K,ConvNext-Base-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
convnext_large_in22k,classification,imagenet21k,convnext_large,Convolutional,Semantic,ConvNext-Large-IN21K,ConvNext-Large-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mixer_b16_224_in21k,classification,imagenet21k,mixer_b16_224,MLP-Mixer,Semantic,Mixer-B16-IN22K,Mixer-B16-IN22K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mixer_l16_224_in21k,classification,imagenet21k,mixer_l16_224,MLP-Mixer,Semantic,Mixer-L16-IN22K,Mixer-L16-IN22K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
mobilenetv3_large_100_miil_in21k,classification,imagenet21k,mobilenetv3_large_100,Convolutional,Semantic,MobileNet-V3-Large-IN21K,MobileNet-V3-Large-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swin_base_patch4_window7_224_in22k,classification,imagenet21k,swin_base_patch4_window7_224,Transformer,Semantic,Swin-B-P4-W7-IN21K,Swin-B-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swin_large_patch4_window7_224_in22k,classification,imagenet21k,swin_large_patch4_window7_224,Transformer,Semantic,Swin-L-P4-W7-IN21K,Swin-L-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
resmlp_big_24_224_in22ft1k,classification,imagenet21k,resmlp_big_24_224,MLP-Mixer,Semantic,ResMLP-Big-24-IN21K,ResMLP-Big-24-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_r50_s16_224_in21k,classification,imagenet21k,vit_base_r50_s16_224,Transformer,Semantic,ViT-B-R50-S16-IN21K,ViT-B-R50-S16-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch16_224_in21k,classification,imagenet21k,vit_base_patch16_224,Transformer,Semantic,ViT-B-P16-IN21K,ViT-B-P16-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch16_224_in21k,classification,imagenet21k,vit_small_patch16_224,Transformer,Semantic,ViT-S-P16-IN21K,ViT-S-P16-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_large_patch16_224_in21k,classification,imagenet21k,vit_large_patch16_224,Transformer,Semantic,ViT-L-P16-IN21K,ViT-L-P16-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch32_224_in21k,classification,imagenet21k,vit_base_patch32_224,Transformer,Semantic,ViT-B-P32-IN21K,ViT-B-P32-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch32_224_in21k,classification,imagenet21k,vit_small_patch32_224,Transformer,Semantic,ViT-S-P32-IN21K,ViT-S-P32-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_large_patch32_224_in21k,classification,imagenet21k,vit_large_patch32_224,Transformer,Semantic,ViT-L-P32-IN21K,ViT-L-P32-IN21K trained on image classification with the ImageNet21K dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ssl_resnet18,semi-supervised,YFCC100M,resnet18,Convolutional,Semantic,ResNet18-SSL,ResNet18-SSL trained on semi-supervised image classification with the YFCC100M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ssl_resnet50,semi-supervised,YFCC100M,resnet50,Convolutional,Semantic,ResNet50-SSL,ResNet50-SSL trained on semi-supervised image classification with the YFCC100M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ssl_resnext101_32x4d,semi-supervised,YFCC100M,resnext101_32x4d,Convolutional,Semantic,ResNext101-32x4D-SSL,ResNext101-32x4D-SSL trained on semi-supervised image classification with the YFCC100M dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swsl_resnet18,semi-weakly-supervised,Instagram,resnet18,Convolutional,Semantic,Resnet18-SWSL,Resnet18-SWSL trained on semi-weakly-supervised image classification with the Instagram dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swsl_resnet50,semi-weakly-supervised,Instagram,resnet50,Convolutional,Semantic,Resnet50-SWSL,Resnet50-SWSL trained on semi-weakly-supervised image classification with the Instagram dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
swsl_resnext101_32x4d,semi-weakly-supervised,Instagram,resnext101_32x4d,Convolutional,Semantic,ResNext101-32x4D-SWSL,ResNext101-32x4D-SWSL trained on semi-weakly-supervised image classification with the Instagram dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_base_patch16_sam_224,sam_pretraining,imagenet,vit_base_patch16_224,Transformer,Semantic,ViT-B-P16-SAM,ViT-B-P16-SAM trained on sharpness-aware pretraining with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
vit_small_patch32_sam_224,sam_pretraining,imagenet,vit_base_patch16_224,Transformer,Semantic,ViT-S-P32-SAM,ViT-S-P32-SAM trained on sharpness-aware pretraining with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b0,classification,imagenet,tf_efficientnet_b0,Convolutional,Semantic,TF-EfficientNet-B0,TF-EfficientNet-B0 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b0_ap,adversarial,imagenet,tf_efficientnet_b0,Convolutional,Semantic,TF-EfficientNet-B0AP,TF-EfficientNet-B0AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b0_ns,noisy_student,imagenet,tf_efficientnet_b0,Convolutional,Semantic,TF-EfficientNet-B0NS,TF-EfficientNet-B0NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b1,classification,imagenet,tf_efficientnet_b1,Convolutional,Semantic,TF-EfficientNet-B1,TF-EfficientNet-B1 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b1_ap,adversarial,imagenet,tf_efficientnet_b1,Convolutional,Semantic,TF-EfficientNet-B1AP,TF-EfficientNet-B1AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b1_ns,noisy_student,imagenet,tf_efficientnet_b1,Convolutional,Semantic,TF-EfficientNet-B1NS,TF-EfficientNet-B1NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b2,classification,imagenet,tf_efficientnet_b2,Convolutional,Semantic,TF-EfficientNet-B2,TF-EfficientNet-B2 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b2_ap,adversarial,imagenet,tf_efficientnet_b2,Convolutional,Semantic,TF-EfficientNet-B2AP,TF-EfficientNet-B2AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b2_ns,noisy_student,imagenet,tf_efficientnet_b2,Convolutional,Semantic,TF-EfficientNet-B2NS,TF-EfficientNet-B2NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b3,classification,imagenet,tf_efficientnet_b3,Convolutional,Semantic,TF-EfficientNet-B3,TF-EfficientNet-B3 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b3_ap,adversarial,imagenet,tf_efficientnet_b3,Convolutional,Semantic,TF-EfficientNet-B3AP,TF-EfficientNet-B3AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b3_ns,noisy_student,imagenet,tf_efficientnet_b3,Convolutional,Semantic,TF-EfficientNet-B3NS,TF-EfficientNet-B3NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b4,classification,imagenet,tf_efficientnet_b4,Convolutional,Semantic,TF-EfficientNet-B4,TF-EfficientNet-B4 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b4_ap,adversarial,imagenet,tf_efficientnet_b4,Convolutional,Semantic,TF-EfficientNet-B4AP,TF-EfficientNet-B4AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b4_ns,noisy_student,imagenet,tf_efficientnet_b4,Convolutional,Semantic,TF-EfficientNet-B4NS,TF-EfficientNet-B4NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b5,classification,imagenet,tf_efficientnet_b5,Convolutional,Semantic,TF-EfficientNet-B5,TF-EfficientNet-B5 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b5_ap,adversarial,imagenet,tf_efficientnet_b5,Convolutional,Semantic,TF-EfficientNet-B5AP,TF-EfficientNet-B5AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b5_ns,noisy_student,imagenet,tf_efficientnet_b5,Convolutional,Semantic,TF-EfficientNet-B5NS,TF-EfficientNet-B5NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b6,classification,imagenet,tf_efficientnet_b6,Convolutional,Semantic,TF-EfficientNet-B6,TF-EfficientNet-B6 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b6_ap,adversarial,imagenet,tf_efficientnet_b6,Convolutional,Semantic,TF-EfficientNet-B6AP,TF-EfficientNet-B6AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b6_ns,noisy_student,imagenet,tf_efficientnet_b6,Convolutional,Semantic,TF-EfficientNet-B6NS,TF-EfficientNet-B6NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b7,classification,imagenet,tf_efficientnet_b7,Convolutional,Semantic,TF-EfficientNet-B7,TF-EfficientNet-B7 trained on image classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b7_ap,adversarial,imagenet,tf_efficientnet_b7,Convolutional,Semantic,TF-EfficientNet-B7AP,TF-EfficientNet-B7AP trained on adversarial classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
tf_efficientnet_b7_ns,noisy_student,imagenet,tf_efficientnet_b7,Convolutional,Semantic,TF-EfficientNet-B7NS,TF-EfficientNet-B7NS trained on noisy student classification with the ImageNet dataset.,timm,https://github.com/rwightman/pytorch-image-models/,
ViT-S-SimCLR,slip,YFCC15M,ViT-S,Transformer,SelfSupervised,ViT-S-SimCLR,ViT-S-SimCLR trained via pure self-supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-S-CLIP,slip,YFCC15M,ViT-S,Transformer,Vision-Language,ViT-S-CLIP,ViT-S-CLIP trained via pure language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-S-SLIP,slip,YFCC15M,ViT-S,Transformer,Vision-Language,ViT-S-SLIP,ViT-S-SLIP trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-B-SimCLR,slip,YFCC15M,ViT-B,Transformer,SelfSupervised,ViT-B-SimCLR,ViT-B-SimCLR trained via pure self-supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-B-CLIP,slip,YFCC15M,ViT-B,Transformer,Vision-Language,ViT-B-CLIP,ViT-B-CLIP trained via pure language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-B-SLIP,slip,YFCC15M,ViT-B,Transformer,Vision-Language,ViT-B-SLIP,ViT-B-SLIP trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-L-SimCLR,slip,YFCC15M,ViT-L,Transformer,SelfSupervised,ViT-L-SimCLR,ViT-L-SimCLR trained via pure self-supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-L-CLIP,slip,YFCC15M,ViT-L,Transformer,Vision-Language,ViT-L-CLIP,ViT-L-CLIP trained via pure language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-L-SLIP,slip,YFCC15M,ViT-L,Transformer,Vision-Language,ViT-L-SLIP,ViT-L-SLIP trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-S-SLIP-Ep100,slip,YFCC15M,ViT-S,Transformer,Vision-Language,ViT-S-SLIP-Ep100,ViT-S-SLIP-Ep100 trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-B-SLIP-Ep100,slip,YFCC15M,ViT-B,Transformer,Vision-Language,ViT-B-SLIP-Ep100,ViT-B-SLIP-Ep100 trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-L-SLIP-Ep100,slip,YFCC15M,ViT-L,Transformer,Vision-Language,ViT-L-SLIP-Ep100,ViT-L-SLIP-Ep100 trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-L-CLIP-CC12M,slip,YFCC15M,ViT-L,Transformer,Vision-Language,ViT-L-CLIP-CC12M,ViT-L-CLIP-CC12M trained via pure language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
ViT-L-SLIP-CC12M,slip,YFCC15M,ViT-L,Transformer,Vision-Language,ViT-L-SLIP-CC12M,ViT-L-SLIP-CC12M trained via combined self- and language supervision with the YFCC15M dataset.,slip,https://github.com/facebookresearch/slip,
RegNet-32Gf-SEER,seer,random1B,RegNet-32Gf,Convolutional,SelfSupervised,RegNet-32Gf-SEER,RegNet-32Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-32Gf-SEER-INFT,seer,random1B,RegNet-32Gf,Convolutional,SelfSupervised,RegNet-32Gf-SEER-INFT,RegNet-32Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-64Gf-SEER,seer,random1B,RegNet-64Gf,Convolutional,SelfSupervised,RegNet-64Gf-SEER,RegNet-64Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-64Gf-SEER-INFT,seer,random1B,RegNet-64Gf,Convolutional,SelfSupervised,RegNet-64Gf-SEER-INFT,RegNet-64Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-128Gf-SEER,seer,random1B,RegNet-128Gf,Convolutional,SelfSupervised,RegNet-128Gf-SEER,RegNet-128Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-128Gf-SEER-INFT,seer,random1B,RegNet-128Gf,Convolutional,SelfSupervised,RegNet-128Gf-SEER-INFT,RegNet-128Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-256Gf-SEER,seer,random1B,RegNet-256Gf,Convolutional,SelfSupervised,RegNet-256Gf-SEER,RegNet-256Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
RegNet-256Gf-SEER-INFT,seer,random1B,RegNet-256Gf,Convolutional,SelfSupervised,RegNet-256Gf-SEER-INFT,RegNet-256Gf trained via large-scale self-supervision on 1 billion images.,seer,https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md#seer,
alexnet_gn_ipcl_imagenet,ipcl,imagenet,alexnet_gn,Convolutional,,AlexNet-GN-IPCLImageNet,AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on ImageNet.,open_ipcl,https://github.com/harvard-visionlab/open_ipcl,
alexnet_gn_ipcl_openimages,ipcl,openimages,alexnet_gn,Convolutional,,AlexNet-GN-IPCLOpenImages,AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on OpenImages.,open_ipcl,https://github.com/harvard-visionlab/open_ipcl,
alexnet_gn_ipcl_places256,ipcl,places256,alexnet_gn,Convolutional,,AlexNet-GN-IPCLPlaces256,AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on Places256.,open_ipcl,https://github.com/harvard-visionlab/open_ipcl,
alexnet_gn_ipcl_vggface2,ipcl,vggface2,alexnet_gn,Convolutional,,AlexNet-GN-IPCLVGGFace2,AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on VGGFace2.,open_ipcl,https://github.com/harvard-visionlab/open_ipcl,
BiT-Expert-ResNet-V2-Food,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Food,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Food subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Vehicle,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Vehicle,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Vehicle subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Instrument,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Instrument,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Instrument subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Flower,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Flower,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Flower subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Animal,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Animal,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Animal subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Object,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Object,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Object subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Bird,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Bird,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Bird subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Mammal,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Mammal,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Mammal subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Arthropod,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Arthropod,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Arthropod subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Relation,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Relation,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Relation subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
BiT-Expert-ResNet-V2-Abstraction,bit_expert,big_transfer,ResNet50-V2,Convolutional,Expertise,BiT-Expert-ResNet-V2-Abstraction,"ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Abstraction subset.",bit_expert,https://tfhub.dev/google/collections/experts/bit/1,
